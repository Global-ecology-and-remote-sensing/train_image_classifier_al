# Train Image Classifier Using Active Learning

The package provides scripts for training an image classifier
using active learning (AL). It attempts to improve the efficiency
of AL algorithms in an image processing context by training an
embedding model that reduces images to a low dimensional space
before active learning is performed. This approach has already
proven useful in a study by Norouzaddeh
et al. in training animal classifiers for camera trap
data (see [acknowledgements](#acknowledgements) for more 
details), however their methods are applicable to any image
classficiation problem. 

Norouzaddeh et al. provided the code that they used in their
experiment, however it lacked several features required to be
used in a practical setting. Most notably, it was neither able to
handle unlabelled data nor label that data. The package provided
here is an adaptation of their code which addresses these issues
and provides a pipeline for employing active learning with some
additional quality of life features.

The main pipeline provided by this package is a function called
"run_active_learning". It trains a model using the approach in
the paper by Norouzaddeh et al. with some additional features
such as providing checkpoints, testing the model and saving the 
model 
in an interoperable format.
If you wish to use your own custom model architecture and training
algorithm then this package could still prove useful by providing
objects that can load-in unlabelled data, label data and keeping
track of what images belong to which datasets (more information
can be found in 
[Designing your own model](#designing-your-own-model)).


**Comment** Why use active learning, active learning's slow computation on
raw images, package uses Norouzaddeh's approach in their paper, it was
adapted from the code that they used in their paper so that it can be
used outside of an experiment. It provides a main script "run_active_learning"
for running active learning but it also provides the objects, active_learning_environment,
data_set and engine which users can use for building their own image processing model.
It also uses both timelapse and AL algorithms designed by Google.

## Why Use Active Learning?

Training neural networks to classify images typically require very
large databases of manually labelled images. In some contexts,
labelling these images can be far more expensive than the
computational resources that are required to train the model. One
way to reduce this cost is to label the images as the model is
being trained. The idea behind this is to choose the best images
to label at each iteration of the training algorithm as to provide
the model with the most information at each stage. Algorithms that
employ this technique are often classed under "active learning".

## Quick Start

**Comment** What you need to run the program, the code that you need to run, 
how to prepare the data, how to label
things with timelapse. Using logging package to see info messages

This package can be installed locally using PIP. To do so, download 
the GitHub repository and run the following code, where the folder
given by "path\to\package" should contain the setup.py file

```python
pip install "path\to\package"
```

This package provides a function for training a model using 
active learning. The only information that it requires to
run are the file paths to the training and unlabelled data,
which must lie in separate directories. An example of how to run
the main program can be seen below.

```python
from camera_trap_al.main_scripts import run_active_learning

run_active_learning(
    train_data = "path\to\train\data",
    unlabelled_data = "path\to\unlabelled\data",
)
```

The program uses
PyTorch's ImageFolder class to read the data. As such, it
requires that images be sorted into subfolders by class. The
training data must contain all of the classes that could appear
in the unlabelled dataset as there is currently no way to add
classes to the data as the model is being trained. All unlabelled
data must also appear in subfolders of its root directory although 
the names of these folders will be ignored and this data will not
be considered to have been labelled. It is important to note that
any image data that lies directly in the data directories and not
inside a subfolder will be ignored. An example on how to structure 
the data can be found on their 
[website](https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html).

The program will display loading bars for parts of the training
algorithm that are known to take a long time, such as during
finetuning and when extracting the image embedding. However,
there are other parts of the program that might take some time
but where progress bars cannot be generated. A log of when
these processes start and stop can be generated by running the
following code before the main function is run.

```python
import logging

logging.getLogger().setLevel(logging.INFO)
```

### Labelling with Timelapse

**Comment** Unfinished. Need to ask Kevin if I can edit the 
document that he gave me so that it has his name on it and that
no camera trap images appear on it.

As per the premise of active learning, the program will ask for
labels as the model is being trained. To do this, it will 
generate a CSV file in the top level of the 
[Active Learning Files](#active-learning-files-folder) folder.
The CSV will have the file name "timelapse_selector.csv" and have
the following columns:

- **File** The file name of the image.
- **RelativePath** path to the image relative root dir for 
unlabelled data (i.e. path passed to "unlabelled_data" parameter)
but without the file name.
- **Selected** Boolean. Entry is true if it needs a label and 
will be False otherwise.

The CSV will contain the file paths for all images in the 
unlabelled folder even if they have already been labelled by the 
program. The "Selected" column shows which images the program has
highlighted as needing labels. All selected images will need to
be labelled before the program can continue training the model.
It should also be noted that the program will ignore any labels 
for images that weren't selected (i.e. where "Selected" was 
False). It is also advised that you keep a record of any and all
labels that you make in case they are improperly recorded by
the program.

To label an image, add a column to the CSV called "Species" that
contains the class name for that image. The class name must
exactly match one of those given by the sub folders of the
"train_data" directory. After you have labelled all of the
selected images in the CSV, save it in the "new_labels_bin" 
folder of the "Active Learning Files" directory and press enter
on the command line. The saved file can have any file name as the
program will simply read the first CSV file that it finds in
there. If the program finds no issues with reading in the CSV
then it will display the message "Labels were loaded 
successfully" and continue training the model.

#### Timelapse

The timelapse selector CSV was designed to be easily read by an
image labelling software known as Timelapse, although any image
labelling tool that adds a column called "Species" to a CSV would
work. Timelapse is an open-source program that is commonly used
by ecologists and animal conservation groups for analysing 
[camera trap](https://en.wikipedia.org/wiki/Camera_trap) data.
This package was orginally designed to help ecologists build
models that can sort databases of animal images by 
automating large parts of the training algorithm, which is why
it is desinged to work with Timelapse and why image labels need
to be placed in a "Species" column.

Details on how to 
[install and set up Timelapse](Timelapse User_Guide.pdf) 
for this package can be found on this GitHub page. 

**Comment** Need to add section on how to label images with
Timelapse

### Using a GPU

There is a known error when trying to use a GPU with this 
package. When the packages PyTorch and Torchvision are installed
while this package is being installed through pip, it will not
install the extension that is required to use these packages with
a GPU. As such, the program will not be able to find your GPU
should you have one in your machine. To work around this, please
uninstall torch and torchvision through pip and re-install it
with the required CUDA extention, which can be found on 
[PyTorch's website](https://pytorch.org/get-started/locally/). 
Of course, you will also need to install CUDA before you can use 
the PyTorch with CUDA extension, which can be found on [NVIDIA's
website](https://developer.nvidia.com/cuda-toolkit). If your
computer does not have an NVIDIA GPU then it currently cannot
be used by this package.

**Comment** Need to uninstall torch and torchvision and then re-install it with cuda.
Also need to install cuda and NVIDIA (maybe provide link to tutorial on using cuda and
NVIDIA)

## Training Algorithm

**Comment** Parameters of main script (No elaboration as that comes later), choices for training algorithm,
I think that when I elaborate, I should use pandas' example of have the parameter and then talk
about it?

The model that is trained by this package is actually two models
that are executed in sequence when they are evaluated. Images are
first passed through the embedding model which performs features
extraction and those features are then passed to the classifier
which makes the final decision. The reason behind splitting the
model into two is to reduce the computational cost of the
active learning process. 

The embedding model is the more complicated model and takes its
architecture and initial weights from a pre-trained neural 
network. The classifier on the other hand is a much simpler 
network with only two hidden layers. The embedding model is
periodically finetuned during training whereas the
classifier is retrained from scratch every time a batch of images
have been labelled. From 
[Norouzaddeh et al's study](#-acknowledgements), performance
tends to improve greatly whenever the embedding model is updated
however there are only incrementaly gains in performance when
the classifier is re-trained.

Almost all of the default values for the hyperparameters are the
same as those found in Norouzaddeh et al.'s code for their
experiment. The following code snippet shows all of the parts
of the training algorithm that can be modified without changing
the source code. The rest of this section describes in more
detail what each of the parameters change. If the program starts
from a checkpoint, parameters that change the 
data sets and the model's architecture will be ignored.

```python
def run_active_learning(
    train_data,
    unlabelled_data,
    validation_data = None,
    validate_model : bool = True,
    use_checkpoints : bool = True,
    num_workers : int = 0,
    active_batch : int = 100, 
    active_learning_strategy : str = 'margin',
    output_dir = 'default',
    use_pretrained : bool = True,
    embedding_arch : str = 'resnet18',
    embedding_loss_type : str =  'triplet',
    embedding_loss_margin : float = 1.0,
    embedding_loss_data_strategy : str = 'random',
    normalize_embedding : bool = True,
    feat_dim : int = 256,
    extract_embedding_batch_size : int = 256,
    embedding_finetuning_period = 2000,
    embedding_finetuning_lr : float = 0.0001,
    embedding_finetuning_weight_decay = 0,
    embedding_finetuning_num_epochs : int = 20,
    embedding_finetuning_loader_type : str = 'balanced',
    embedding_train_lr : float = 0.00001,
    embedding_train_weight_decay = 0.0005,
    embedding_train_num_epochs : int = 5,
    embedding_train_loader_type : str = 'single',
    balanced_loader_num_classes : int = 20,
    balanced_loader_num_samples : int = 10,
)
```

### Data

**Comment** Format of data folders, train set needs all labels, unlabelled needs to be
in subfolders, validation set of classes can be a subset of the training ones

Ignored when loaded by checkpoint : True

All image files must lie in subfolders of their data directory.
Any images that lie in the top level of their directory will be
ignored. For labelled data, the names of the subfolders in the
top-level of the directory will be taken as the class name for
all images that are in those folders. The names of the subfolders
for the unlabelled directory will be ignored and no
top-level subfolders can contain no images. 
Additionally, There is
currently no way to add data to the AL program after the model
has been initially trained. 

**Parameters**:

- **train_data** : Data that the model is intially trained on
 before active learning is performed.
 Expects an absolute file path to a directory of images
 Subfolders of the top
 level of this directory must contain all of the classes that
 could be found in the unlabelled dataset. If you think that you
 might find images that do not belong to any of your classes then
 it is advised to add an "Other" class that these images could be
 assigned to.
 
- **unlabelled_data** : Data that has yet to be labelled. 
 Expects an absolute file path to a directory of images
 Images
 that are labelled through the active learning process will not
 be moved from this folder even if they would technically be
 considered as labelled at that point. Therefore, if a checkpoint
 is deleted and external record of the new labels have been made
 then those labels be lost. Furthermore, if you wish to retrain
 the model from scratch using labels that you had made from a
 previous execution of the program then an external program would
 be required to move those labelled images from the unlabelled
 dataset to the train dataset.
 
- **validation_data** : Data used to test the model as it is
 being trained. Expects an absolute file path to a directory of 
 images. Classes of this dataset can be a subset of those in the
 train data but the names of the classes that are included must
 exactly match those in the train data. The model is tested every
 time new labels are added to the data and the test results can
 be found in the [test results folder](#-validation-results) of 
 the Active Learning Files folder.

### Training Loop Parameters

Ignored when loaded by checkpoint : False

**Parameters**:
 
- **validate_model** : Boolean. If True and if a test set exists,
 test results will be generated during training. Otherwise, no
 tests will be performed.

- **use_checkpoints** : If True if a checkpoint exists, function 
 will load model and data mappings from that checkpoint. 
 Otherwise, it will train a model from scratch. Checkpoints are 
 always overwritten by this program and so any progress made by 
 old checkpoints will be lost if this is set to False.

- **num_workers** : Number of workers that will train the 
 embeddingmodel
 and extract features in parallel. **WARNING** num_workers must 
 be set to 0 if running on a Windows machine or else the program
 will freeze indefinitely. This is because Windows OS blocks 
 multi-processing requests from PyTorch.

### Active learning

**Comment** AL batch size, available sampling methods



### Embedding model

**Comment** Available architectures, triplet loss vs softmax, 
(I don't know what the triplet loss hyperparameters do)

### Train and finetune embedding

**Comment** Adam sampler, available hyperparameters, importance of num_epochs, balanced vs simple loader

### Classifier

**Comment** No way to edit classifier as it's hardcoded into the source code :(

## Active Learning Files Folder

**Comment** This is where all files generated by the package are
saved

### Checkpoint folders

**Comment** Needed for checkpoints, don't change or move these
folders if you want to load from checkpoint

### Label bin

**Comment** Covered by previous section but described here for completion

### Validation results

**Comment** Stored in test results folder, to save model for
latest test results, you'll have to copy the export
folder before you submit the labels for that AL batch,
Does not exist if validation doesn't exist

### Exporting model

**Comment** Trained model for latest test results

## Troubleshooting

**Comment** Building data loader and loading model from
checkpoint typically takes a long time so please be patient.

## Designing your own model

**Comment** Brief comment on which classes might be useful
and that you can use run_active_learning.py as an example

## Cite

**Comment** How to cite the package

## Acknowledgements

It uses the approach described in the
paper called "A deep active learning system for species 
identification and counting in camera trap images" by Norouzaddeh
et al., which tries to improve the efficieny of the training
algorithm by performing active learning on the features extracted
from the data rather than the images themselves.

**Comment** Acknwoledgments to Megadetector, Norouzaddeh,
Google team for AL algorithms