# Train Image Classifier Using Active Learning

Training neural networks to classify images typically require 
very large databases of manually labelled images. 


Camera traps are cameras with a motion sensor that take a picture
whenever something moves in front of them. They are often
used as an inexpensive and non-invasive method of observing animals 
in the wild. This has allowed researchers to generate large databases
of animal activity that typically take a long
time to manually sort through before they can be used
in a research project.

This package provides an easy-to-use function that automatically identifies
the species of an animal in a picture. It has the added feature of cropping the images
around the animal and sorting them into folders by species but it also requires that the animals first be 
detected using [MegaDetector](#megadetector) before the program is run.
The function was originally designed to work for a model that
was trained to categorise animals found in Hong Kong, however it should be relatively easy
to adapt it for any model trained with Keras 
(see the section on how to [modify the pipeline](#how-to-modify-the-package-for-a-new-model) 
for details).

The modules in this repository should be seen as the second part of a larger pipeline
for sorting animal images. MegaDetector provides the first step of finding the
animals in the database and this package automates the final step of categorising
those animals.


**Comment** Why use active learning, active learning's slow computation on
raw images, package uses Norouzaddeh's approach in their paper, it was
adapted from the code that they used in their paper so that it can be
used outside of an experiment. It provides a main script "run_active_learning"
for running active learning but it also provides the objects, active_learning_environment,
data_set and engine which users can use for building their own image processing model.
It also uses both timelapse and AL algorithms designed by Google.

## Quick start

**Comment** What you need to run the program, the code that you need to run, 
how to prepare the data, how to label
things with timelapse. Using logging package to see info messages

## Training Algorithm

**Comment** Parameters of main script (No elaboration as that comes later), choices for training algorithm,
I think that when I elaborate, I should use pandas' example of have the parameter and then talk
about it?

### Data

**Comment** Format of data folders, train set needs all labels, unlabelled needs to be
in subfolders, validation set of classes can be a subset of the training ones

### Active Learning

**Comment** AL batch size, available sampling methods

### Embedding model

**Comment** Available architectures, triplet loss vs softmax, 
(I don't know what the triplet loss hyperparameters do)

### Train and finetune embedding

**Comment** Adam sampler, available hyperparameters, importance of num_epochs, balanced vs simple loader

### Classifier

**Comment** No way to edit classifier as it's hardcoded into the source code :(

## Working folder

**Comment** This is where all files generated by the package are
saved

### Checkpoint folders

**Comment** Needed for checkpoints, don't change or move these
folders if you want to load from checkpoint

### label bin

**Comment** Covered by previous section but described here for completion

### Validation results

**Comment** Stored in test results folder, to save model for
latest test results, you'll have to copy the export
folder before you submit the labels for that AL batch,
Does not exist if validation doesn't exist

### Exporting model

**Comment** Trained model for latest test results

# Designing your own model